{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41f829c7-4c10-4ea9-a662-37bb28f075f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 3 - create_table_user_yt_from_wikipedia_api\n",
    "\n",
    "Este notebook enriquece a base de criadores a partir das páginas da Wikipedia, realizando scraping controlado e distribuído da API oficial.  \n",
    "O fluxo inclui:  \n",
    "- leitura da tabela `default.creators_scrape_wiki` com os nomes das páginas;  \n",
    "- chamadas paralelas à API da Wikipedia para coletar links externos de cada página;  \n",
    "- aplicação de padrões (regex) para extrair o identificador de canal do YouTube (`user_id`);  \n",
    "- escrita incremental na tabela **default.users_yt** via MERGE (upsert);  \n",
    "- registro de falhas ou páginas sem link em uma tabela de erros (**default.users_yt_errors**) com documentação das causas.  \n",
    "\n",
    "O resultado é um mapeamento atualizado e confiável de `wiki_page → user_id` para uso nas análises seguintes.  \n",
    "\n",
    "\n",
    "Obs. a utilização de mapInPandas é\n",
    "necessária devido ao compute disponível no Databricks Community (Serveless - Spark Connect) não suportar APIs de RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "36aba83a-cf2c-4e4f-aeed-6c17885950c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58f5e851-e46f-46fd-acd3-2d34b9e0f4be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faff0f9f-3b4a-49d4-a832-daa1a2b59bbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Libraries and configuration\n",
    "import re, time, random, logging\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import Iterator\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from delta.tables import DeltaTable\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "# Widgets (parameterization)\n",
    "dbutils.widgets.text(\"source_table\", \"default.creators_scrape_wiki\", \"Tabela de origem (wiki_page)\")\n",
    "dbutils.widgets.text(\"target_table\", \"default.users_yt\", \"Tabela destino (users_yt)\")\n",
    "dbutils.widgets.text(\"error_table\", \"default.users_yt_errors\", \"Tabela de erros\")\n",
    "dbutils.widgets.text(\"partitions\", \"6\", \"Nº de partições (paralelismo)\")\n",
    "dbutils.widgets.text(\"base_sleep\", \"0.4\", \"Pausa (s) entre requests\")\n",
    "dbutils.widgets.text(\"max_retries\", \"3\", \"Máx tentativas por request\")\n",
    "dbutils.widgets.text(\"timeout_s\", \"15\", \"Timeout por request (s)\")\n",
    "\n",
    "source_table   = dbutils.widgets.get(\"source_table\").strip()\n",
    "target_table   = dbutils.widgets.get(\"target_table\").strip()\n",
    "error_table    = dbutils.widgets.get(\"error_table\").strip()\n",
    "N_PARTITIONS   = int(dbutils.widgets.get(\"partitions\"))\n",
    "BASE_SLEEP     = float(dbutils.widgets.get(\"base_sleep\"))\n",
    "MAX_RETRIES    = int(dbutils.widgets.get(\"max_retries\"))\n",
    "REQUEST_TIMEOUT= int(dbutils.widgets.get(\"timeout_s\"))\n",
    "\n",
    "# in production switch to Databricks secrets\n",
    "contact_email  = \"edanniel.d@gmail.com\"\n",
    "\n",
    "WIKI_API   = \"https://en.wikipedia.org/w/api.php\"\n",
    "USER_AGENT = f\"databricks-challenge/1.0 (contato: {contact_email})\"\n",
    "\n",
    "# Extraction rules\n",
    "YT_PATTERNS = [\n",
    "    re.compile(r\"https?://(?:www\\.)?youtube\\.com/user/([A-Za-z0-9_\\-\\.]+)\", re.IGNORECASE),\n",
    "    re.compile(r\"https?://(?:www\\.)?youtube\\.com/@([A-Za-z0-9_\\-\\.]+)\",    re.IGNORECASE),  \n",
    "    re.compile(r\"https?://(?:www\\.)?youtube\\.com/c/([A-Za-z0-9_\\-\\.]+)\",   re.IGNORECASE),\n",
    "    re.compile(r\"https?://(?:www\\.)?youtube\\.com/channel/([A-Za-z0-9_\\-]+)\", re.IGNORECASE),\n",
    "]\n",
    "\n",
    "def extract_user_id_from_urls(urls: list[str]) -> str | None:\n",
    "    if not urls:\n",
    "        return None\n",
    "    for rx in YT_PATTERNS:\n",
    "        for u in urls:\n",
    "            m = rx.search(str(u))\n",
    "            if m:\n",
    "                return m.group(1).strip().lower()\n",
    "    return None\n",
    "\n",
    "def fetch_external_links(session: requests.Session, page: str) -> list[str]:\n",
    "    \"\"\"Returns list of external links via action=parse&prop=externallinks.\"\"\"\n",
    "    params = {\"action\": \"parse\", \"page\": page, \"prop\": \"externallinks\", \"format\": \"json\", \"redirects\": 1}\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            r = session.get(WIKI_API, params=params, timeout=REQUEST_TIMEOUT)\n",
    "            if r.status_code == 429:\n",
    "                time.sleep(BASE_SLEEP * attempt + random.uniform(0, 0.5))\n",
    "                continue\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            return data.get(\"parse\", {}).get(\"externallinks\", []) or []\n",
    "        except requests.RequestException as e:\n",
    "            logging.warning(f\"[try {attempt}] falha em '{page}': {e}\")\n",
    "            if attempt == MAX_RETRIES:\n",
    "                return []\n",
    "            time.sleep(BASE_SLEEP * attempt + random.uniform(0, 0.5))\n",
    "    return []\n",
    "\n",
    "# mapInPandas: 1 HTTP session per partition (instead of pandas.apply)\n",
    "result_schema = StructType([\n",
    "    StructField(\"wiki_page\", StringType(), True),\n",
    "    StructField(\"user_id\",   StringType(), True),\n",
    "    StructField(\"error\",     StringType(), True),\n",
    "])\n",
    "\n",
    "def fetch_yt_users_batch(pdfs: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    # prepare session with connection pool (reuse) per partition:\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\"User-Agent\": USER_AGENT, \"Accept-Encoding\": \"gzip\"})\n",
    "    # increase pool for internal session parallelism \n",
    "    session.mount(\"https://\", HTTPAdapter(pool_connections=10, pool_maxsize=10))\n",
    "    try:\n",
    "        for pdf in pdfs:\n",
    "            rows_out = []\n",
    "            # explicit iteration\n",
    "            for page in pdf[\"wiki_page\"].astype(str).tolist():\n",
    "                if not page or page.lower() in {\"nan\", \"none\"}:\n",
    "                    rows_out.append({\"wiki_page\": None, \"user_id\": None, \"error\": \"empty_page\"})\n",
    "                    continue\n",
    "                urls = fetch_external_links(session, page)\n",
    "                user_id = extract_user_id_from_urls(urls)\n",
    "                err = None if user_id else \"user_id_not_found\"\n",
    "                rows_out.append({\"wiki_page\": page, \"user_id\": user_id, \"error\": err})\n",
    "                time.sleep(BASE_SLEEP)  # be polite with the API\n",
    "            yield pd.DataFrame(rows_out)\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "# Source and incremental\n",
    "src_df = (\n",
    "    spark.table(source_table)\n",
    "         .select(F.trim(F.col(\"wiki_page\")).alias(\"wiki_page\"))\n",
    "         .where(F.col(\"wiki_page\").isNotNull() & (F.col(\"wiki_page\") != \"\"))\n",
    "         .distinct()\n",
    ")\n",
    "\n",
    "# incremental (anti-join)\n",
    "try:\n",
    "    if spark.catalog.tableExists(target_table):\n",
    "        done = spark.table(target_table).select(\"wiki_page\").distinct()\n",
    "        src_df = src_df.join(done, \"wiki_page\", \"left_anti\")\n",
    "except Exception as e:\n",
    "    logging.info(f\"Anti-join não aplicado, processando tudo. Motivo: {e}\")\n",
    "\n",
    "# check without isEmpty()\n",
    "if src_df.limit(1).count() == 0:\n",
    "    logging.info(\"Sem novas wiki_page para processar.\")\n",
    "    dbutils.notebook.exit(\"OK: nada novo para processar.\")\n",
    "\n",
    "# Distributed execution\n",
    "users_df = (\n",
    "    src_df.repartition(N_PARTITIONS)\n",
    "          .mapInPandas(fetch_yt_users_batch, schema=result_schema)\n",
    ")\n",
    "\n",
    "ok_df = (\n",
    "    users_df.filter(F.col(\"user_id\").isNotNull())\n",
    "            .select(\"wiki_page\", \"user_id\")\n",
    "            .dropDuplicates([\"wiki_page\"])\n",
    ")\n",
    "errors_df = (\n",
    "    users_df.filter(F.col(\"user_id\").isNull())\n",
    "            .select(\"wiki_page\", \"error\")\n",
    ")\n",
    "\n",
    "# Persistence (Delta)\n",
    "# create tables if they don’t exist\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {target_table} (\n",
    "  wiki_page STRING,\n",
    "  user_id   STRING\n",
    ") USING delta\n",
    "\"\"\")\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {error_table} (\n",
    "  wiki_page STRING,\n",
    "  error     STRING\n",
    ") USING delta\n",
    "\"\"\")\n",
    "\n",
    "# MERGE\n",
    "DeltaTable.forName(spark, target_table) \\\n",
    "    .alias(\"tgt\").merge(\n",
    "        source=ok_df.alias(\"src\"),\n",
    "        condition=\"tgt.wiki_page = src.wiki_page\"\n",
    "    ).whenMatchedUpdate(set={\"user_id\": \"src.user_id\"}) \\\n",
    "     .whenNotMatchedInsert(values={\"wiki_page\": \"src.wiki_page\", \"user_id\": \"src.user_id\"}) \\\n",
    "     .execute()\n",
    "\n",
    "# erros (append)\n",
    "if errors_df.limit(1).count() > 0:\n",
    "    errors_df.write.format(\"delta\").mode(\"append\").saveAsTable(error_table)\n",
    "\n",
    "# Metadata and comments\n",
    "spark.sql(f\"\"\"\n",
    "ALTER TABLE {target_table}\n",
    "SET TBLPROPERTIES (\n",
    "  'pipeline.step' = 'create_table_user_yt_from_wikipedia_api',\n",
    "  'source.table'  = '{source_table}'\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"COMMENT ON COLUMN {target_table}.wiki_page IS 'Nome da página Wikipedia do criador (ex: Felipe_Neto)'\")\n",
    "spark.sql(f\"COMMENT ON COLUMN {target_table}.user_id IS 'UserID/Handle/Channel extraído do YouTube (ex: felipeneto, UC...)'\")\n",
    "\n",
    "spark.sql(f\"COMMENT ON TABLE {target_table} IS 'Mapeamento wiki_page -> user_id (YouTube) por scraping da Wikipedia';\")\n",
    "\n",
    "# Documentation of the error table\n",
    "spark.sql(f\"\"\"\n",
    "  COMMENT ON TABLE {error_table}\n",
    "  IS 'Registro de páginas da Wikipedia que não geraram user_id do YouTube durante o scraping (falhas ou ausência de link).'\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  COMMENT ON COLUMN {error_table}.wiki_page\n",
    "  IS 'Nome da página na Wikipedia que foi tentada (ex.: Felipe_Neto).'\n",
    "\"\"\")\n",
    "spark.sql(f\"\"\"\n",
    "  COMMENT ON COLUMN {error_table}.error\n",
    "  IS 'Motivo da falha: empty_page | user_id_not_found | mensagem de exceção HTTP/parse.'\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Validation\n",
    "# display(spark.sql(f\"\"\"\n",
    "# SELECT COUNT(*) AS total_rows, COUNT(user_id) AS with_user_id FROM {target_table}\n",
    "# \"\"\"))\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "3 - create_table_user_yt_from_wikipedia_api",
   "widgets": {
    "base_sleep": {
     "currentValue": "0.4",
     "nuid": "5de1d839-6f79-4180-b523-63426e0734e5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "0.4",
      "label": "Pausa (s) entre requests",
      "name": "base_sleep",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "0.4",
      "label": "Pausa (s) entre requests",
      "name": "base_sleep",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "error_table": {
     "currentValue": "default.users_yt_errors",
     "nuid": "1e77c48c-6e58-46ac-bdbb-e607c1bcec7d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "default.users_yt_errors",
      "label": "Tabela de erros",
      "name": "error_table",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "default.users_yt_errors",
      "label": "Tabela de erros",
      "name": "error_table",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "max_retries": {
     "currentValue": "3",
     "nuid": "1c5f1074-f496-4d25-9e08-154b3e1fc75b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "3",
      "label": "Máx tentativas por request",
      "name": "max_retries",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "3",
      "label": "Máx tentativas por request",
      "name": "max_retries",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "partitions": {
     "currentValue": "6",
     "nuid": "09cda95c-138e-4ee6-b02f-f1f5a4def6d5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "6",
      "label": "Nº de partições (paralelismo)",
      "name": "partitions",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "6",
      "label": "Nº de partições (paralelismo)",
      "name": "partitions",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "source_table": {
     "currentValue": "default.creators_scrape_wiki",
     "nuid": "2bb34f84-cbe9-43bf-8268-24a5ff315ee5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "default.creators_scrape_wiki",
      "label": "Tabela de origem (wiki_page)",
      "name": "source_table",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "default.creators_scrape_wiki",
      "label": "Tabela de origem (wiki_page)",
      "name": "source_table",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "target_table": {
     "currentValue": "default.users_yt",
     "nuid": "ce93cf8d-cc3d-4c4f-b934-a9231a8b41b9",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "default.users_yt",
      "label": "Tabela destino (users_yt)",
      "name": "target_table",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "default.users_yt",
      "label": "Tabela destino (users_yt)",
      "name": "target_table",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "timeout_s": {
     "currentValue": "15",
     "nuid": "eefbd195-3a3d-40b6-9f49-07002feca43f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "15",
      "label": "Timeout por request (s)",
      "name": "timeout_s",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "15",
      "label": "Timeout por request (s)",
      "name": "timeout_s",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
